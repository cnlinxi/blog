# arpa2fst将语言模型转为WFST

## 概述

在基于WFST的语音识别中，需要将HCLG或TLG不同层次的WFST复合在一起构成超大的解码网络，其中G就是语音模型的WFST表示。但常见的语言模型并不是以WFST形式存在，而是基于ngram实现，并以arpa文件形式存在。

arpa2fst可以将语言模型arpa文件转换为WFST，便于后续解码图的构建。

## 语言模型

语言模型通常以arpa文件形式存在，示例如下：

```

\data\
ngram1=9
ngram2=10
ngram3=2

\1-grams:
-0.7533277 </s>
-99 <s> -0.7907404
-0.9294189 今天 -1.059586
-1.230449 北京 -0.6268836
-0.7533277 天气 -0.5177391
-0.7533277 怎么 -0.5177391
-1.230449 明天 -0.5688916
-0.7533277 样 -0.5177391
-1.230449 的 -0.5688916

\2-grams:
-0.39794 <s> 今天
-0.3309932 <s> 明天
-0.3309932 今天 北京
-0.3309932 今天 天气
-0.1091445 北京 的
-0.1249387 天气 怎么 0
-0.1249387 怎么 样 0
-0.1091445 明天 天气
-0.1249387 样 </s>
-0.1091445 的 天气

\3-grams:
-0.1249387天气 怎么 样
-0.1249387怎么 样 </s>
\end\
```

arpa文件的每一行表示一个文法项，它通常包含三部分内容：

```

probability word(s) [backoff probability]
```

其中，`probability`表示该词或词组发生的概率，`word(s)`表示具体的词或者词组，`[backoff probablitiy]`是可选项，表示回退概率，当下层文法有以当前词或词组为前缀的文法项时，回退概率存在。例如上述示例中，二元文法项`天气 怎么`是三元文法项`天气 怎么 样`的前缀，所以它存在回退概率，在上述示例中该回退概率为0，通常不为0。

通过上述的arpa文件，可以计算给定一句话的语言模型得分，假设arpa文件中最高元为三元，则句子`ABCDEF`发生的概率为：

$$
P(ABCDEF)=P(A)\times P(B|A)\times P(C|AB)\times P(D|BC)\times P(E|CD)\times P(F|DE)
$$

其中，$P(A)$通过查询arpa文件中1-grams文法项获得。如果2-gram存在词组`A B`，则$P(B|A)$也可以通过查询2-grams文法项获得；如果词组`A B`在2-grams中不存在，就需要利用回退概率计算$P(B|A)$，计算公式为：

$$
P(B|A)=\alpha(A)\times P(B)
$$

其中，$\alpha(A)$表示`A`的回退概率。类似地，三元词组概率的计算公式如下：

$$
P(C|AB)=P(C|AB)\quad if\ A\ B\ C\ exists
$$

$$
 P(C|AB)=\alpha(AB)\times P(C|B)\quad if\ B\ C\ exists
$$

$$
 P(C|AB)=\alpha(AB)\times \alpha(B) \times P(C)\quad other
$$

## WFSA转换为WFST

WFST比WFSA多了输出标签，如果不考虑语言模型和发音词典的融合，arpa2fst只需要将arpa转换为WFSA即可，但语音识别中语言模型并非单独存在，而是需要和其它解码器图复合，构成最终的WFST解码网络，需要语言模型生成的WFST存在输入和输出符号。对语言模型来说，WFSA转换到WFST非常容易，只需要将每条边上的输入标签复制成输出标签即可。如下图为语言模型示例通过arpa2fst生成的WFST：

![](attachments/Pasted%20image%2020220531162056.png)

如上图所示，转移弧权重$w$和语言模型的对数（10为底）概率$L$之间的计算关系为：

$$
w=-{\rm ln}(10^L)
$$

比如1-gram中“今天”的对数概率为-0.9294189，则图中权重为$w=-{\rm ln}(10^{-0.9294189})=2.1401$。概率值取负对数作为图中的权重，此时权重的意义为路径代价（Cost），即权重越大，概率越小。为了使G在去掉$\epsilon$之后能够被确定化，在每个回退跳转的后面加入一个符号`#0`，图中`<eps>`表示空标签$\epsilon$。经过这这样的展开，任意序列的语言模型**负对数累积概率**就等于图中**某路径的累计权重**。

![](attachments/Pasted%20image%2020220531213405.png)

某个二元语言模型对应的WFST如上图所示，其中每个节点表示一个词，节点之间的转移弧权重表示前一个词$w_1$与后一个词$w_2$之间的条件概率$P(w_2|w_1)$。例如，节点1表示句子的起始`<s>`，节点2表示`今天`，从节点1到2的转移弧为`今天:今天/0.40547`，转移弧上的权重（即条件概率）与语言模型对数概率之间的计算关系如上式，即$0.40547=-{\rm ln}(10^{-0.1760913})$。如上文所述，如果$w_1$和$w_2$构成的词组在语言模型中不存在，则$w_1$和$w_2$之间的条件概率由$w_1$回退概率和$w_2$概率相乘得到。比如，上图中节点0表示回退状态，节点1到节点0的转移弧权重为0.8473，对应`<s>`的回退概率-0.3679768，即$0.8473=-{\rm ln}(10^{-0.3679768})$。节点2到节点0的转移弧权重为0.69315，对应`今天`的回退概率为-0.30103，即$0.69315=-{\rm ln}(10^{-0.30103})$。

> [arpa2fst 原理详解_yutianzuijin的博客-CSDN博客_arpa文件](https://blog.csdn.net/yutianzuijin/article/details/78756130)
> 洪青阳-《语音识别原理与实践》-P.168
> [WFST 语言模型 - 简书](https://www.jianshu.com/p/095939c4617f)